### 混淆矩阵

少数类(关注的类)记为**正样本**，用 1 表示。多数类(其他类)记为**负样本**，用 0 表示。

预测为正样本记为P，预测为负样本记为N。

预测值与真实值相同记为T，预测值与真实值相反记为F。

|          | 预测值 1 | 预测值0 |
| :------- | -------- | ------- |
| 真实值 1 | TP       | FN      |
| 真实值 0 | FP       | TN      |



| metric |            |                                   |
| ------ | ---------- | --------------------------------- |
| 真正率 | TP/(TP+FN) | 被预测为正的正样本数/实际正样本数 |
| 假负率 | FN/(TP+FN) | 被预测为负的正样本数/实际正样本数 |
| 真负率 | TN/(TN+FP) | 被预测为负的负样本数/实际负样本数 |
| 假正率 | FP/(TN+FP) | 被预测为正的负样本数/实际负样本数 |



#### Accuracy 准确率

预测正确率
$$
Acc = \frac {TP + TN} {TP + TN + FP + FN}
$$
#### Precision 精确率

预测的所有正样本中，真实为正样本的概率。 
$$
Precision = \frac {TP}{TP + FP}
$$
#### Recall 召回率

所有真实的正样本中被预测为正样本的概率。
$$
Recall = \frac {TP}{TP + FN}
$$
#### F1 分数

兼顾precision和recall，是它俩的调和平均， 倾向于较小的那个。
$$
F1 = \frac {2} {\frac {1}{Precision} + \frac {1}{Recall}}
$$
#### ROC Curve

Receiver Operating Characteristic Curve

横坐标：假正率  FP率

纵坐标：召回率  TP率

作用：1确定阈值 2得到 AUC



#### AUC

ROC曲线下方面积

0.5 - 0.7：效果较低，但用于预测股票已经很不错了
0.7 - 0.85：效果一般
0.85 - 0.95：效果很好
0.95 - 1：效果非常好，但一般不太可能



#### 回归评估

##### 1 MAE 平均平方误差，又称L1范数损失

$$
\text{MAE} = \frac1m  \sum_{i=1}^m (y_i - \hat{y}_i)^2
$$



##### 2 RMSE 平方根误差

$$
\text{RMSE} = \sqrt{\frac1m  \sum_{i=1}^m (y_i - \hat{y}_i)^2}
$$



##### 3 $R^2$ 判定系数

$$
R^2 = \frac{SSR}{SST}=1-\frac{SSE}{SST}=1-\frac{\sum_{i=1}^m (y_i - \hat{y}_i)^2}{\sum_{i=1}^m (y_i - \overline{y}_i)^2}
$$



SSR回归平方和，SSE残差，SST总离差平方和

##### 4 PPE

PPE10 误差/真实值 < 10%为正确

| 真实 | 预测 | 误差 | 误差占比 | 结果      |
| ---- | ---- | ---- | -------- | --------- |
| 100  | 95   | 5    | 5/100    | <10% 正确 |
| 200  | 175  | 25   | 25/200   | >10% 错误 |
| 300  | 280  | 20   | 20/300   | <10% 正确 |

PPE10 = 2/3 = 66.6%



#### 聚类评估

##### 1 误差平方和 （SSE）

$$
\text{SSE} = \sum_{i=1}^k\sum_{p \in C_i}{|p-m_i|^2}
$$

- m 为簇的中心点，p 为簇内的点， C 为一个簇， k 为簇的个数。
- 肘点法则：下降率突然变缓时即认为是最佳k值。
- 刻画了簇内凝聚程度。

##### 2 轮廓系数（SI）

​		对于每一个点i，计算：
$$
S(i) = \frac{b(i)-a(i)}{\text{max}{\{a(i), b(i)\}}}
$$

- a(i)   点  i 与同一簇内其他点的不相似程度均值 
- b(i)   点  i 与其他簇的点平均不相似程度的最小值
- 可选取两个簇距离最近的两个点的距离定义为两个簇之间的距离。
- 轮廓系数的值介于 [-1, 1]， 趋近1代表内聚度和分离度都相对较优。
- 将所有点的轮廓系数求平均，就是该聚类结果总的轮廓系数。

##### 3 CH系数  （Calinski-Harabasz Index）

$$
\text{SSB} =  \sum_{i=1}^k n_i ||u_i - u||^2
$$

$$
\text{SSW} = \sum_{i=1}^k \sum_{x \in C_i}^{n_i}||x_i - u_i||
$$

$$
\text{VRC} = \cfrac{\cfrac{\text{SSB}}{k-1}}{\cfrac{\text{SSW}}{N-k}}
$$



- $u_i$为各簇的均值，$u$为总均值，$x_i$为簇内各点。
- VRC越大意味着聚类质量越好



### 语言模型评估指标

#### 困惑度 perplexity

衡量一个概率分布或概率模型预测样本的好坏程度。

困惑度越小，句子概率越大，语言模型越好。
$$
PP(S) = \sqrt[N]{\prod_{i=1}^{N} \frac{1}{p(w_i | w_2 ... w_{i-1})}}
$$

### 机器翻译评价指标

#### BLEU

Bilingual evaluation  understudy，分数取值范围是0~1

一般用 **C** 表示机器翻译的译文，另外还需要提供 m 个参考的翻译 **S1**, **S2**, ..., **Sm**。评价指标就可以衡量机器翻译的 **C** 和参考翻译 **S1**, **S2**, ..., **Sm** 的匹配程度。
$$
BLEU = BP * \text{exp}(\sum_{n=1}^N W_n * \text{log}P_n) \\
$$

$$
BP = 
\begin{cases}
1, &lc\ \gt\ lr\\
\text{exp}(1-lr/lc), &lc\ \le\ lr
\end{cases}
$$

lc = 机器译文的长度   lr = 最短的参考翻译句子的长度

BLEU需要计算译文1-gram、2-gram、...、N-gram的精确率，一般N设置为4

![img](https://upload-images.jianshu.io/upload_images/20030902-14cdcaf389e0e52f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

$W_n$指n-gram的权重，一般设置为均匀权重

BP是惩罚因子，如果译文长度小于最短的参考译文，则BP小于1。当机器翻译的长度比较短时，BLEU 得分也会比较高，但是这个翻译是会损失很多信息，因此需要在 BLEU 分数乘上惩罚因子。

BLEU的1-gram精确率表示译文忠于原文的程度，而其他n-gram表示翻译的流畅程度。



#### ROUGE

##### ROUGE-N

$$
\text{ROUGE-N} = \frac{统计参考译文与机器译文共有的N-gram个数}{统计参考译文中N-gram的个数}
$$

假设有 M 个译文 **S1**, ..., **SM**。ROUGE-N 会分别计算机器译文和这些参考译文的 ROUGE-N 分数，并取其最大值。

##### ROUGE-L

该指标关注机器译文C和参考译文S的最长公共子序列Longest Common Subsequence。
$$
Recall_{LCS} = \frac {LCS(C,S)}{len(S)}
$$

$$
Precision_{LCS} = \frac {LCS(C,S)}{len(C)}
$$

![img](https://upload-images.jianshu.io/upload_images/20030902-7c479d96e3914ae0.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

$F_{LCS}$ 就是 ROUGE-L。一般 $\beta$ 会设置为很大的数，因此 $F_{LCS}$ 几乎只考虑或者说更关注$R_{LCS}$ (即召回率)

##### ROUGE-W

提升了ROUGE-L 在最长公共子序列上连续性的敏感度。

##### ROUGE-S

ROUGE-S 也是对 N-gram 进行统计，但是其采用的 N-gram 允许"跳词 (Skip)"，即单词不需要连续出现。例如句子 "I have a cat" 的 Skip 2-gram 包括 (I, have)，(I, a)，(I, cat)，(have, a)，(have, cat)，(a, cat)。

reference:

https://www.jianshu.com/p/0afb93fda403

